(()=>{var e={};e.id=895,e.ids=[895],e.modules={7849:e=>{"use strict";e.exports=require("next/dist/client/components/action-async-storage.external")},2934:e=>{"use strict";e.exports=require("next/dist/client/components/action-async-storage.external.js")},5403:e=>{"use strict";e.exports=require("next/dist/client/components/request-async-storage.external")},4580:e=>{"use strict";e.exports=require("next/dist/client/components/request-async-storage.external.js")},4749:e=>{"use strict";e.exports=require("next/dist/client/components/static-generation-async-storage.external")},5869:e=>{"use strict";e.exports=require("next/dist/client/components/static-generation-async-storage.external.js")},399:e=>{"use strict";e.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},4443:(e,t,a)=>{"use strict";a.r(t),a.d(t,{GlobalError:()=>o.a,__next_app__:()=>m,originalPathname:()=>u,pages:()=>d,routeModule:()=>p,tree:()=>l}),a(8088),a(4457),a(5866);var i=a(3191),s=a(8716),r=a(7922),o=a.n(r),n=a(5231),c={};for(let e in n)0>["default","tree","pages","GlobalError","originalPathname","__next_app__","routeModule"].indexOf(e)&&(c[e]=()=>n[e]);a.d(t,c);let l=["",{children:["projects",{children:["__PAGE__",{},{page:[()=>Promise.resolve().then(a.bind(a,8088)),"C:\\Users\\sugho\\Projects\\Shreya\\app\\projects\\page.tsx"]}]},{}]},{layout:[()=>Promise.resolve().then(a.bind(a,4457)),"C:\\Users\\sugho\\Projects\\Shreya\\app\\layout.tsx"],"not-found":[()=>Promise.resolve().then(a.t.bind(a,5866,23)),"next/dist/client/components/not-found-error"]}],d=["C:\\Users\\sugho\\Projects\\Shreya\\app\\projects\\page.tsx"],u="/projects/page",m={require:a,loadChunk:()=>Promise.resolve()},p=new i.AppPageRouteModule({definition:{kind:s.x.APP_PAGE,page:"/projects/page",pathname:"/projects",bundlePath:"",filename:"",appPaths:[]},userland:{loaderTree:l}})},4286:(e,t,a)=>{Promise.resolve().then(a.bind(a,1123))},1123:(e,t,a)=>{"use strict";a.d(t,{default:()=>r});var i=a(326),s=a(3141);function r({title:e,description:t,children:a,className:r="",id:o}){return(0,i.jsxs)(s.E.section,{id:o,className:`my-16 ${r}`,initial:{opacity:0,y:20},whileInView:{opacity:1,y:0},viewport:{once:!0},transition:{duration:.6},children:[(0,i.jsxs)("div",{className:"mb-8",children:[i.jsx("h2",{className:"text-3xl md:text-4xl font-bold text-zinc-900 dark:text-zinc-100 mb-4 font-serif",children:e}),t&&i.jsx("p",{className:"text-lg text-zinc-600 dark:text-zinc-400 leading-relaxed max-w-3xl",children:t})]}),i.jsx("div",{className:"grid gap-6",children:a})]})}},8088:(e,t,a)=>{"use strict";a.r(t),a.d(t,{default:()=>n,metadata:()=>o});var i=a(9510);let s=JSON.parse('[{"id":"rtmri-toolkit","title":"rtMRI Processing Toolkit","summary":"Comprehensive utilities for frame extraction, segmentation, and kinematic cues from real-time MRI data.","description":"A Python-based toolkit for processing and analyzing real-time MRI data in speech production research. Includes automated segmentation, motion tracking, and visualization tools.","year":2024,"status":"Active","tags":["rtMRI","Python","Image Processing","Speech Research"],"technologies":["Python","OpenCV","NumPy","Matplotlib","scikit-image"],"link":"#","github":"#","features":["Automated frame extraction from rtMRI videos","Articulatory structure segmentation","Kinematic parameter extraction","Interactive visualization tools"]},{"id":"ema-visualization","title":"EMA Visualization Suite","summary":"Interactive plots and metrics for articulatory trajectories from electromagnetic articulography data.","description":"MATLAB-based visualization suite for analyzing and presenting EMA data with interactive plotting capabilities and statistical analysis tools.","year":2024,"status":"Active","tags":["EMA","MATLAB","Data Visualization","Articulatory Analysis"],"technologies":["MATLAB","Statistics Toolbox","Signal Processing Toolbox"],"link":"#","github":"#","features":["Interactive trajectory plotting","Statistical analysis of articulatory movements","Customizable visualization parameters","Export capabilities for publications"]},{"id":"coarticulation-analysis","title":"Co-articulation Analysis Framework","summary":"Framework for analyzing co-articulatory effects in speech production using multi-modal data.","description":"A comprehensive framework combining rtMRI and EMA data to study co-articulatory effects in speech production, with focus on velum dynamics and tongue shape variability.","year":2023,"status":"Completed","tags":["Co-articulation","rtMRI","EMA","Speech Production"],"technologies":["MATLAB","Python","Statistical Analysis"],"link":"#","github":"#","features":["Multi-modal data integration","Co-articulatory effect quantification","Statistical modeling","Publication-ready visualizations"]}]');var r=a(6930);let o={title:"Projects – Shreya Karkun"};function n(){return i.jsx(r.ZP,{title:"Projects",description:"Selected tools and experiments.",children:i.jsx("div",{className:"grid md:grid-cols-2 gap-4",children:s.map((e,t)=>(0,i.jsxs)("article",{className:"card p-5",children:[i.jsx("h3",{className:"font-semibold",children:e.title}),i.jsx("p",{className:"text-sm mt-2 opacity-90",children:e.summary}),(0,i.jsxs)("div",{className:"mt-2 text-xs",children:[e.tags.join(" • ")," • ",e.year]}),e.link&&i.jsx("a",{className:"underline text-sm mt-2 inline-block",href:e.link,children:"Learn more"})]},t))})})}},6930:(e,t,a)=>{"use strict";a.d(t,{ZP:()=>n});var i=a(8570);let s=(0,i.createProxy)(String.raw`C:\Users\sugho\Projects\Shreya\components\Section.tsx`),{__esModule:r,$$typeof:o}=s;s.default;let n=(0,i.createProxy)(String.raw`C:\Users\sugho\Projects\Shreya\components\Section.tsx#default`)}};var t=require("../../webpack-runtime.js");t.C(e);var a=e=>t(t.s=e),i=t.X(0,[948,378,916],()=>a(4443));module.exports=i})();